{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directories for training and testing data\n",
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/validation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create a dataframe for images and their labels\n",
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataframe for training and testing data\n",
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract features from images\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, color_mode='grayscale')\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28821/28821 [02:33<00:00, 187.42it/s]\n",
      "100%|██████████| 7066/7066 [00:38<00:00, 181.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features for training and testing datasets\n",
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])\n",
    "\n",
    "# Normalize the data by dividing by 255\n",
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label encoding and one-hot encoding the labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,        # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,    # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,   # randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.2,           # randomly zoom in on images\n",
    "    horizontal_flip=True,     # randomly flip images horizontally\n",
    "    fill_mode='nearest'       # filling in new pixels when images are rotated or shifted\n",
    ")\n",
    "\n",
    "# Use the data generator on the training set\n",
    "train_datagen = datagen.flow(x_train, y_train, batch_size=128)\n",
    "\n",
    "# No data augmentation for the validation/test set\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_datagen_flow = test_datagen.flow(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\Important Documents\\Manan\\2 UK\\MSc\\Dissertation\\archive\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\Important Documents\\Manan\\2 UK\\MSc\\Dissertation\\archive\\env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 392ms/step - accuracy: 0.2353 - loss: 1.8388 - val_accuracy: 0.2583 - val_loss: 1.8095\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 385ms/step - accuracy: 0.2502 - loss: 1.8078 - val_accuracy: 0.2540 - val_loss: 1.7878\n",
      "Epoch 3/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 386ms/step - accuracy: 0.2473 - loss: 1.7922 - val_accuracy: 0.2577 - val_loss: 1.7787\n",
      "Epoch 4/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 382ms/step - accuracy: 0.2504 - loss: 1.7854 - val_accuracy: 0.2924 - val_loss: 1.7308\n",
      "Epoch 5/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 380ms/step - accuracy: 0.2666 - loss: 1.7611 - val_accuracy: 0.3020 - val_loss: 1.7028\n",
      "Epoch 6/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 379ms/step - accuracy: 0.2791 - loss: 1.7465 - val_accuracy: 0.3258 - val_loss: 1.6653\n",
      "Epoch 7/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.2863 - loss: 1.7308 - val_accuracy: 0.3372 - val_loss: 1.6548\n",
      "Epoch 8/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 364ms/step - accuracy: 0.2891 - loss: 1.7273 - val_accuracy: 0.3453 - val_loss: 1.6153\n",
      "Epoch 9/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.3018 - loss: 1.7080 - val_accuracy: 0.3807 - val_loss: 1.5576\n",
      "Epoch 10/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.3117 - loss: 1.6921 - val_accuracy: 0.4076 - val_loss: 1.5315\n",
      "Epoch 11/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 333ms/step - accuracy: 0.3281 - loss: 1.6639 - val_accuracy: 0.4285 - val_loss: 1.4694\n",
      "Epoch 12/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.3382 - loss: 1.6563 - val_accuracy: 0.4608 - val_loss: 1.4137\n",
      "Epoch 13/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.3541 - loss: 1.6249 - val_accuracy: 0.4466 - val_loss: 1.4215\n",
      "Epoch 14/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 327ms/step - accuracy: 0.3559 - loss: 1.6188 - val_accuracy: 0.4714 - val_loss: 1.3724\n",
      "Epoch 15/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 330ms/step - accuracy: 0.3652 - loss: 1.6050 - val_accuracy: 0.4621 - val_loss: 1.3715\n",
      "Epoch 16/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.3762 - loss: 1.5843 - val_accuracy: 0.4860 - val_loss: 1.3421\n",
      "Epoch 17/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 325ms/step - accuracy: 0.3843 - loss: 1.5752 - val_accuracy: 0.4626 - val_loss: 1.3645\n",
      "Epoch 18/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 327ms/step - accuracy: 0.3797 - loss: 1.5728 - val_accuracy: 0.4890 - val_loss: 1.3184\n",
      "Epoch 19/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.3913 - loss: 1.5624 - val_accuracy: 0.5006 - val_loss: 1.3062\n",
      "Epoch 20/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.3953 - loss: 1.5580 - val_accuracy: 0.4987 - val_loss: 1.3115\n",
      "Epoch 21/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 325ms/step - accuracy: 0.4031 - loss: 1.5427 - val_accuracy: 0.5168 - val_loss: 1.2753\n",
      "Epoch 22/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4070 - loss: 1.5272 - val_accuracy: 0.5007 - val_loss: 1.3079\n",
      "Epoch 23/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4088 - loss: 1.5191 - val_accuracy: 0.5195 - val_loss: 1.2761\n",
      "Epoch 24/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4068 - loss: 1.5240 - val_accuracy: 0.5245 - val_loss: 1.2665\n",
      "Epoch 25/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4077 - loss: 1.5228 - val_accuracy: 0.5048 - val_loss: 1.2804\n",
      "Epoch 26/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4111 - loss: 1.5082 - val_accuracy: 0.5123 - val_loss: 1.2749\n",
      "Epoch 27/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4174 - loss: 1.4967 - val_accuracy: 0.5190 - val_loss: 1.2644\n",
      "Epoch 28/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4144 - loss: 1.5074 - val_accuracy: 0.5242 - val_loss: 1.2450\n",
      "Epoch 29/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 325ms/step - accuracy: 0.4165 - loss: 1.4980 - val_accuracy: 0.5282 - val_loss: 1.2343\n",
      "Epoch 30/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 327ms/step - accuracy: 0.4266 - loss: 1.4919 - val_accuracy: 0.5292 - val_loss: 1.2337\n",
      "Epoch 31/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4274 - loss: 1.4792 - val_accuracy: 0.5379 - val_loss: 1.2243\n",
      "Epoch 32/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 322ms/step - accuracy: 0.4314 - loss: 1.4670 - val_accuracy: 0.5416 - val_loss: 1.2154\n",
      "Epoch 33/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 324ms/step - accuracy: 0.4313 - loss: 1.4862 - val_accuracy: 0.5382 - val_loss: 1.2118\n",
      "Epoch 34/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4359 - loss: 1.4722 - val_accuracy: 0.5456 - val_loss: 1.2100\n",
      "Epoch 35/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 322ms/step - accuracy: 0.4303 - loss: 1.4689 - val_accuracy: 0.5485 - val_loss: 1.2119\n",
      "Epoch 36/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4311 - loss: 1.4693 - val_accuracy: 0.5464 - val_loss: 1.2234\n",
      "Epoch 37/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 323ms/step - accuracy: 0.4360 - loss: 1.4590 - val_accuracy: 0.5392 - val_loss: 1.2254\n",
      "Epoch 38/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4339 - loss: 1.4686 - val_accuracy: 0.5422 - val_loss: 1.2101\n",
      "Epoch 39/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4436 - loss: 1.4448 - val_accuracy: 0.5463 - val_loss: 1.1980\n",
      "Epoch 40/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 351ms/step - accuracy: 0.4384 - loss: 1.4474 - val_accuracy: 0.5345 - val_loss: 1.2282\n",
      "Epoch 41/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 362ms/step - accuracy: 0.4396 - loss: 1.4539 - val_accuracy: 0.5573 - val_loss: 1.1947\n",
      "Epoch 42/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.4375 - loss: 1.4462 - val_accuracy: 0.5464 - val_loss: 1.2015\n",
      "Epoch 43/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4390 - loss: 1.4552 - val_accuracy: 0.5507 - val_loss: 1.1897\n",
      "Epoch 44/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4513 - loss: 1.4369 - val_accuracy: 0.5508 - val_loss: 1.1915\n",
      "Epoch 45/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4453 - loss: 1.4450 - val_accuracy: 0.5378 - val_loss: 1.2122\n",
      "Epoch 46/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4392 - loss: 1.4515 - val_accuracy: 0.5553 - val_loss: 1.1868\n",
      "Epoch 47/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4533 - loss: 1.4348 - val_accuracy: 0.5500 - val_loss: 1.1836\n",
      "Epoch 48/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4505 - loss: 1.4323 - val_accuracy: 0.5652 - val_loss: 1.1802\n",
      "Epoch 49/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4529 - loss: 1.4286 - val_accuracy: 0.5425 - val_loss: 1.1956\n",
      "Epoch 50/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4528 - loss: 1.4224 - val_accuracy: 0.5592 - val_loss: 1.1808\n",
      "Epoch 51/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 351ms/step - accuracy: 0.4473 - loss: 1.4375 - val_accuracy: 0.5652 - val_loss: 1.1749\n",
      "Epoch 52/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4491 - loss: 1.4340 - val_accuracy: 0.5511 - val_loss: 1.1934\n",
      "Epoch 53/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 355ms/step - accuracy: 0.4509 - loss: 1.4350 - val_accuracy: 0.5600 - val_loss: 1.1820\n",
      "Epoch 54/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4556 - loss: 1.4233 - val_accuracy: 0.5597 - val_loss: 1.1664\n",
      "Epoch 55/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4511 - loss: 1.4351 - val_accuracy: 0.5718 - val_loss: 1.1541\n",
      "Epoch 56/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4583 - loss: 1.4205 - val_accuracy: 0.5643 - val_loss: 1.1749\n",
      "Epoch 57/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4521 - loss: 1.4228 - val_accuracy: 0.5573 - val_loss: 1.1598\n",
      "Epoch 58/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 351ms/step - accuracy: 0.4577 - loss: 1.4202 - val_accuracy: 0.5597 - val_loss: 1.1730\n",
      "Epoch 59/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4606 - loss: 1.4147 - val_accuracy: 0.5568 - val_loss: 1.1605\n",
      "Epoch 60/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4513 - loss: 1.4150 - val_accuracy: 0.5669 - val_loss: 1.1578\n",
      "Epoch 61/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4582 - loss: 1.4223 - val_accuracy: 0.5573 - val_loss: 1.1527\n",
      "Epoch 62/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4634 - loss: 1.4102 - val_accuracy: 0.5616 - val_loss: 1.1534\n",
      "Epoch 63/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4672 - loss: 1.3996 - val_accuracy: 0.5678 - val_loss: 1.1550\n",
      "Epoch 64/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 351ms/step - accuracy: 0.4632 - loss: 1.4051 - val_accuracy: 0.5638 - val_loss: 1.1595\n",
      "Epoch 65/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 356ms/step - accuracy: 0.4594 - loss: 1.4069 - val_accuracy: 0.5590 - val_loss: 1.1690\n",
      "Epoch 66/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 353ms/step - accuracy: 0.4681 - loss: 1.4005 - val_accuracy: 0.5589 - val_loss: 1.1734\n",
      "Epoch 67/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4631 - loss: 1.4083 - val_accuracy: 0.5582 - val_loss: 1.1722\n",
      "Epoch 68/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4601 - loss: 1.4068 - val_accuracy: 0.5716 - val_loss: 1.1542\n",
      "Epoch 69/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4625 - loss: 1.4005 - val_accuracy: 0.5539 - val_loss: 1.1598\n",
      "Epoch 70/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 350ms/step - accuracy: 0.4639 - loss: 1.4006 - val_accuracy: 0.5563 - val_loss: 1.1714\n",
      "Epoch 71/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4643 - loss: 1.3965 - val_accuracy: 0.5610 - val_loss: 1.1492\n",
      "Epoch 72/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 352ms/step - accuracy: 0.4745 - loss: 1.3916 - val_accuracy: 0.5672 - val_loss: 1.1607\n",
      "Epoch 73/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 360ms/step - accuracy: 0.4645 - loss: 1.4000 - val_accuracy: 0.5637 - val_loss: 1.1456\n",
      "Epoch 74/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 362ms/step - accuracy: 0.4688 - loss: 1.3903 - val_accuracy: 0.5676 - val_loss: 1.1447\n",
      "Epoch 75/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 361ms/step - accuracy: 0.4697 - loss: 1.3903 - val_accuracy: 0.5669 - val_loss: 1.1406\n",
      "Epoch 76/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 364ms/step - accuracy: 0.4679 - loss: 1.4016 - val_accuracy: 0.5733 - val_loss: 1.1462\n",
      "Epoch 77/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 360ms/step - accuracy: 0.4701 - loss: 1.3883 - val_accuracy: 0.5679 - val_loss: 1.1427\n",
      "Epoch 78/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 360ms/step - accuracy: 0.4670 - loss: 1.3949 - val_accuracy: 0.5658 - val_loss: 1.1508\n",
      "Epoch 79/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4679 - loss: 1.3849 - val_accuracy: 0.5606 - val_loss: 1.1611\n",
      "Epoch 80/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4704 - loss: 1.3894 - val_accuracy: 0.5777 - val_loss: 1.1385\n",
      "Epoch 81/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4770 - loss: 1.3807 - val_accuracy: 0.5624 - val_loss: 1.1488\n",
      "Epoch 82/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 360ms/step - accuracy: 0.4710 - loss: 1.3902 - val_accuracy: 0.5684 - val_loss: 1.1474\n",
      "Epoch 83/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4715 - loss: 1.3944 - val_accuracy: 0.5719 - val_loss: 1.1460\n",
      "Epoch 84/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.4778 - loss: 1.3730 - val_accuracy: 0.5594 - val_loss: 1.1630\n",
      "Epoch 85/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4751 - loss: 1.3789 - val_accuracy: 0.5753 - val_loss: 1.1450\n",
      "Epoch 86/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4762 - loss: 1.3761 - val_accuracy: 0.5760 - val_loss: 1.1325\n",
      "Epoch 87/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 362ms/step - accuracy: 0.4725 - loss: 1.3861 - val_accuracy: 0.5720 - val_loss: 1.1405\n",
      "Epoch 88/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4705 - loss: 1.3883 - val_accuracy: 0.5757 - val_loss: 1.1343\n",
      "Epoch 89/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.4777 - loss: 1.3757 - val_accuracy: 0.5771 - val_loss: 1.1261\n",
      "Epoch 90/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4708 - loss: 1.3926 - val_accuracy: 0.5708 - val_loss: 1.1557\n",
      "Epoch 91/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4762 - loss: 1.3770 - val_accuracy: 0.5744 - val_loss: 1.1312\n",
      "Epoch 92/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4780 - loss: 1.3701 - val_accuracy: 0.5674 - val_loss: 1.1381\n",
      "Epoch 93/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4766 - loss: 1.3825 - val_accuracy: 0.5736 - val_loss: 1.1382\n",
      "Epoch 94/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 361ms/step - accuracy: 0.4727 - loss: 1.3861 - val_accuracy: 0.5698 - val_loss: 1.1291\n",
      "Epoch 95/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4842 - loss: 1.3598 - val_accuracy: 0.5778 - val_loss: 1.1373\n",
      "Epoch 96/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4758 - loss: 1.3790 - val_accuracy: 0.5693 - val_loss: 1.1387\n",
      "Epoch 97/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4713 - loss: 1.3784 - val_accuracy: 0.5764 - val_loss: 1.1303\n",
      "Epoch 98/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4766 - loss: 1.3789 - val_accuracy: 0.5761 - val_loss: 1.1257\n",
      "Epoch 99/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 363ms/step - accuracy: 0.4717 - loss: 1.3820 - val_accuracy: 0.5692 - val_loss: 1.1232\n",
      "Epoch 100/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 359ms/step - accuracy: 0.4732 - loss: 1.3768 - val_accuracy: 0.5757 - val_loss: 1.1417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x221208c4320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model with augmented data\n",
    "model.fit(train_datagen, epochs=100, validation_data=test_datagen_flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector4.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector4.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved model and weights\n",
    "json_file = open(\"emotiondetector4.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector4.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediction function\n",
    "label = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "def ef(image):\n",
    "    img = load_img(image, color_mode='grayscale')\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "model prediction is sad\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example prediction\n",
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is\", pred_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
